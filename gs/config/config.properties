inference_address=http://0.0.0.0:8095
management_address=http://0.0.0.0:8091
metrics_address=http://0.0.0.0:8092
grpc_inference_port=7070
grpc_management_port=7071
enable_envvars_config=true	
enable_metrics_api=true
metrics_format=prometheus
NUM_WORKERS=8
number_of_netty_threads=8
job_queue_size=20
load_models=all
number_of_gpu=1
gpu_id=0
install_py_dep_per_model=true
model_store=/mnt/models/model-store	
model_snapshot={"name": "startup.cfg", "modelCount": 1, "models": {"pipeline": {"1.0": {"defaultVersion": true, "marName": "pipeline.mar", "minWorkers": 1, "maxWorkers": 3, "batchSize": 4, "maxBatchDelay": 100, "responseTimeout": 120}}}}